{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrewKSr5zY4L"
   },
   "source": [
    "# 0- Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XR5kZH3dzLao"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcKqoqX-zXEW"
   },
   "source": [
    "# 1- Overall architecture\n",
    "* Architecture: **Yolov8's model in the tranning phase**\n",
    "<a href=\"https://ibb.co/6gpLnd3\"><img src=\"https://i.ibb.co/NZkbV48/yolov8-training.png\" alt=\"yolov8-training\" border=\"0\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9WSUIpfznPC"
   },
   "source": [
    "## 1.1- The input to model and label encoder during the training phase\n",
    "\n",
    "<a href=\"https://ibb.co/1J751qC\"><img src=\"https://i.ibb.co/WpGwZyr/yolov8-label-encoder.png\" alt=\"yolov8-label-encoder\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDxJgzXQ--W7"
   },
   "source": [
    "## 1.2- Model's output\n",
    "<a href=\"https://ibb.co/JKL7s4W\"><img src=\"https://i.ibb.co/KXZqrkc/yolov8-output.png\" alt=\"yolov8-output\" border=\"0\"></a>\n",
    "\n",
    "\n",
    "The output is reshaped according to the following steps:\n",
    "<a href=\"https://ibb.co/bXtx5Pr\"><img src=\"https://i.ibb.co/m4pm5GH/yolov8-output-reshape.png\" alt=\"yolov8-output-reshape\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhKmlkFp-JKX"
   },
   "source": [
    "## 1.3- Model's architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l82tsqd9-OFb"
   },
   "source": [
    "### 1.3.1- Anchor points\n",
    "* Yolov8 outputs 3 feature maps of shape: $80 \\times 80, 40 \\times 40$ and $20 \\times 20$.\n",
    "* **Anchor points** are points on these output feature maps; they are the points of a grid placed on the feature maps by sampling x and y axis at $[0.5, 1.0, 1.5, 2.0, \\cdots, size-0.5]$; where $size$ is the feature map's size; i.e., $80, 40$ or $20$.\n",
    "    * We are able to convert the anchor points to image space by multiplying their coordinates with the stride for each each feature map. The anchor points can be seen as in the following picture (in image space).\n",
    "    * ```stride = image-size /feature-size```. There are 3 feature maps, their size corresponds to $8, 16$ and $32$.\n",
    "\n",
    "<a href=\"https://ibb.co/Yfh2wCJ\"><img src=\"https://i.ibb.co/5sLTw0C/anchorpoints.png\" alt=\"anchorpoints\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2- Anchor points: Purpose\n",
    "*  Anchor points are used to **encode** and to **decode** ground-truth boxes and predicted-boxes.\n",
    "*  Each anchor point is associated with a predicted box and vice versa.\n",
    "*  The figure below describe the relationship between an anchor point and its predicted boxes.\n",
    "*  \n",
    "\n",
    "<a href=\"https://ibb.co/rFB7KnB\"><img src=\"https://i.ibb.co/vVNwC2N/yolov8-anchor-enc-dec.png\" alt=\"yolov8-anchor-enc-dec\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2hyqAMCBCkN"
   },
   "source": [
    "### 1.4.2- Meaning of model's output\n",
    "* Yolov8 predicts the following information for $N_a$ candidate boxes; where,  $N_a$ is the total number of anchor points.\n",
    "  * (1) **Classes probabilities**: there are $N_c$ classes; so, there are $N_c$ probabilities, each is the range $[0, 1]$ (Yolov8 try to support multilabel) for each boxes.\n",
    "  * (2) Distribution of $LT.dx; LT.dy; RB.dx; RB.dy$. Yolov8 uses **categorical distribution** to approximate the distribution of those displacement.\n",
    "      * $N_r$: range of a displacement; i.e., any displacement can have the value within $[0, N_r-1]$\n",
    "      * Therefore, for each candidate boxes, Yolov8 output $N_r (e.g., 16)$ values for each of $LT.dx; LT.dy; RB.dx; RB.dy$.\n",
    "      * $N_r$ values for a box's displacement are passed to softmax function to output the distribution.\n",
    "      * In the case that we want to determine the displacement, we compute the expectation: $\\sum_{x=0}^{x=N_r}{x\\times p(x)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRSemdi5C_Un"
   },
   "source": [
    "### 1.4.3- The model\n",
    "<a href=\"https://ibb.co/dp8rp8W\"><img src=\"https://i.ibb.co/bvcPvcW/Yolov8.png\" alt=\"Yolov8\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzrq8nVyEMKX"
   },
   "source": [
    "# 2-LossMeter\n",
    "<a href=\"https://ibb.co/CQ1ZyjY\"><img src=\"https://i.ibb.co/dDWqvNV/yolov8-loss-meter.png\" alt=\"yolov8-loss-meter\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IqDOk_XLUBR"
   },
   "source": [
    "### 2.1- Matching ground-truth vs candidate boxes:\n",
    "<a href=\"https://ibb.co/sJVSWFv\"><img src=\"https://i.ibb.co/yBQT48n/yolov8-matcher.png\" alt=\"yolov8-matcher\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EBo88ONzrFm"
   },
   "source": [
    "## 2.2 Distribution Focal Loss (DFL Loss)\n",
    "* DFL-Loss:\n",
    "\n",
    "<a href=\"https://ibb.co/C7NN8Sn\"><img src=\"https://i.ibb.co/yyGGPx8/yolov8-dfl-loss.png\" alt=\"yolov8-dfl-loss\" border=\"0\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN33GHv8sUWfyWMPCft3Hta",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
